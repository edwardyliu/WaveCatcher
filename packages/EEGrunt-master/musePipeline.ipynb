{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1552683620495_recording.csv', '1552684135826_recording.csv', '1552684518897_recording.csv', '1552684885683_recording.csv', '1552685274491_recording.csv', '1552686579599_recording.csv', '1552687068355_recording.csv', '1552687461872_recording.csv', '1552687730763_recording.csv', '1552688006554_recording.csv', '1552684886225_recording.csv', '1552685478381_recording.csv', '1552685952146_recording.csv', '1552686877018_recording.csv', '1552687454762_recording.csv', '1552687746756_recording.csv', '1552882289936_recording.csv', '1550862070278_recording.csv', '1551117337203_recording.csv', '1551117646871_recording.csv', '1551118061985_recording.csv', '1551118320943_recording.csv', '1551249571278_recording.csv', '1553039903059_recording.csv', '1553040206684_recording.csv', '1553040672641_recording.csv', '1553041018556_recording.csv', '1553041309127_recording.csv', '1553041571909_recording.csv', '1553041964221_recording.csv', '1553042270815_recording.csv', '1553042628553_recording.csv', '1552687266553_recording.csv', '1552687653488_recording.csv', '1552687968261_recording.csv', '1552793083454_recording.csv', '1552793419397_recording.csv', '1552794169380_recording.csv', '1552794648660_recording.csv']\n",
      "['Simon', 'Music', 'Music', 'Music', 'Simon', 'Simon', 'Music', 'Music', 'Music', 'Music', 'Simon', 'Music', 'Music', 'Simon', 'Music', 'Music', 'Simon', 'Music', 'Music', 'Music', 'Music', 'Music', 'Simon', 'Simon', 'Music', 'Music', 'Music', 'Music', 'Music', 'Music', 'Music', 'Music', 'Simon', 'Simon', 'Music', 'Music', 'Simon', 'Music', 'Simon']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Load metadata\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "files = []\n",
    "labels = []\n",
    "persons = [\"Ashima Gupta\", \"Achinth Venkat\", \"Oishe Farhan\", \"Liu Edward\"]\n",
    "with open('../../datasets/raw/users.json') as jsonfile:\n",
    "    metadata = json.load(jsonfile)\n",
    "    for person in persons:\n",
    "        #print(person)\n",
    "        for session in metadata[person]['sessions']:\n",
    "            activity = metadata[person]['sessions'][session]['activity']\n",
    "            #print(activity, end=': ')\n",
    "            #print(session)\n",
    "            files.append(session)\n",
    "            labels.append(activity)\n",
    "        #print()\n",
    "print(files)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV 1552683620495_recording.csv - 1 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552683620495_recording.csv - 1 of 39.\n",
      "Reading CSV 1552684135826_recording.csv - 2 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552684135826_recording.csv - 2 of 39.\n",
      "Reading CSV 1552684518897_recording.csv - 3 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552684518897_recording.csv - 3 of 39.\n",
      "Reading CSV 1552684885683_recording.csv - 4 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552684885683_recording.csv - 4 of 39.\n",
      "Reading CSV 1552685274491_recording.csv - 5 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552685274491_recording.csv - 5 of 39.\n",
      "Reading CSV 1552686579599_recording.csv - 6 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552686579599_recording.csv - 6 of 39.\n",
      "Reading CSV 1552687068355_recording.csv - 7 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687068355_recording.csv - 7 of 39.\n",
      "Reading CSV 1552687461872_recording.csv - 8 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687461872_recording.csv - 8 of 39.\n",
      "Reading CSV 1552687730763_recording.csv - 9 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687730763_recording.csv - 9 of 39.\n",
      "Reading CSV 1552688006554_recording.csv - 10 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552688006554_recording.csv - 10 of 39.\n",
      "Reading CSV 1552684886225_recording.csv - 11 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552684886225_recording.csv - 11 of 39.\n",
      "Reading CSV 1552685478381_recording.csv - 12 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552685478381_recording.csv - 12 of 39.\n",
      "Reading CSV 1552685952146_recording.csv - 13 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552685952146_recording.csv - 13 of 39.\n",
      "Reading CSV 1552686877018_recording.csv - 14 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552686877018_recording.csv - 14 of 39.\n",
      "Reading CSV 1552687454762_recording.csv - 15 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687454762_recording.csv - 15 of 39.\n",
      "Reading CSV 1552687746756_recording.csv - 16 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687746756_recording.csv - 16 of 39.\n",
      "Reading CSV 1552882289936_recording.csv - 17 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552882289936_recording.csv - 17 of 39.\n",
      "Reading CSV 1550862070278_recording.csv - 18 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1550862070278_recording.csv - 18 of 39.\n",
      "Reading CSV 1551117337203_recording.csv - 19 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1551117337203_recording.csv - 19 of 39.\n",
      "Reading CSV 1551117646871_recording.csv - 20 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1551117646871_recording.csv - 20 of 39.\n",
      "Reading CSV 1551118061985_recording.csv - 21 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1551118061985_recording.csv - 21 of 39.\n",
      "Reading CSV 1551118320943_recording.csv - 22 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1551118320943_recording.csv - 22 of 39.\n",
      "Reading CSV 1551249571278_recording.csv - 23 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1551249571278_recording.csv - 23 of 39.\n",
      "Reading CSV 1553039903059_recording.csv - 24 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553039903059_recording.csv - 24 of 39.\n",
      "Reading CSV 1553040206684_recording.csv - 25 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553040206684_recording.csv - 25 of 39.\n",
      "Reading CSV 1553040672641_recording.csv - 26 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553040672641_recording.csv - 26 of 39.\n",
      "Reading CSV 1553041018556_recording.csv - 27 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553041018556_recording.csv - 27 of 39.\n",
      "Reading CSV 1553041309127_recording.csv - 28 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553041309127_recording.csv - 28 of 39.\n",
      "Reading CSV 1553041571909_recording.csv - 29 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553041571909_recording.csv - 29 of 39.\n",
      "Reading CSV 1553041964221_recording.csv - 30 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553041964221_recording.csv - 30 of 39.\n",
      "Reading CSV 1553042270815_recording.csv - 31 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553042270815_recording.csv - 31 of 39.\n",
      "Reading CSV 1553042628553_recording.csv - 32 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1553042628553_recording.csv - 32 of 39.\n",
      "Reading CSV 1552687266553_recording.csv - 33 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687266553_recording.csv - 33 of 39.\n",
      "Reading CSV 1552687653488_recording.csv - 34 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687653488_recording.csv - 34 of 39.\n",
      "Reading CSV 1552687968261_recording.csv - 35 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552687968261_recording.csv - 35 of 39.\n",
      "Reading CSV 1552793083454_recording.csv - 36 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552793083454_recording.csv - 36 of 39.\n",
      "Reading CSV 1552793419397_recording.csv - 37 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552793419397_recording.csv - 37 of 39.\n",
      "Reading CSV 1552794169380_recording.csv - 38 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552794169380_recording.csv - 38 of 39.\n",
      "Reading CSV 1552794648660_recording.csv - 39 of 39: \n",
      "\tTruncating DataFrame: ... Complete.\n",
      "\tSplitting DataFrame: ... Complete.\n",
      "Complete 1552794648660_recording.csv - 39 of 39.\n",
      "Saving New DataFrames & Labels: ... Complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Load file-by-file --> split into 'time' second intervals\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fs = 256\n",
    "trim = 5 # seconds\n",
    "time = 15 # seconds\n",
    "overlap = 2 #seconds\n",
    "\n",
    "raw_path = '../../datasets/raw/'\n",
    "raw_topath = '../../datasets/pulse/'\n",
    "\n",
    "pulse_files = []\n",
    "pulse_labels = []\n",
    "for idx, file in enumerate(files):\n",
    "    print(\"Reading CSV {} - {} of {}: \".format(file, idx+1, len(files)))\n",
    "    df = pd.read_csv(raw_path+file)\n",
    "    \n",
    "    df = df.loc[:, ['time', 'TP9', 'AF7', 'AF8', 'TP10']]\n",
    "    \n",
    "    print(\"\\tTruncating DataFrame: \", end='...')\n",
    "    df = df.truncate(before=trim*fs, after=df.shape[0]-trim*fs-1)\n",
    "    print(\" Complete.\")\n",
    "    \n",
    "    print(\"\\tSplitting DataFrame: \", end='...')\n",
    "    start = 0\n",
    "    for end in range(time*fs, df.shape[0], time*fs-1):\n",
    "        if end > df.shape[0]:\n",
    "            break\n",
    "        \n",
    "        if start == 0:\n",
    "            pulse_files.append(df[start:end+overlap*fs-1])\n",
    "        elif end+overlap*fs > df.shape[0]:\n",
    "            pulse_files.append(df[df.shape[0]-(time+overlap)*fs:df.shape[0]-1])\n",
    "        else:\n",
    "            pulse_files.append(df[start-overlap*fs:end])\n",
    "        \n",
    "        if labels[idx] == 'Simon':\n",
    "            pulse_labels.append(1)\n",
    "        else:\n",
    "            pulse_labels.append(0)\n",
    "        start = end\n",
    "    print(\" Complete.\")\n",
    "    print(\"Complete {} - {} of {}.\".format(file, idx+1, len(files)))\n",
    "\n",
    "print(\"Saving New DataFrames & Labels: \", end='...')\n",
    "\n",
    "\n",
    "for idx, pulse in enumerate(pulse_files):\n",
    "    name = raw_topath+str(idx)+'.csv'\n",
    "    pulse.to_csv(path_or_buf=name, index=False)\n",
    "pulse_labels = np.array(pulse_labels)\n",
    "np.save(file='../../datasets/labels.npy', arr=pulse_labels)\n",
    "\n",
    "print(\" Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889\n",
      "(4351, 5)\n",
      "(889, 4351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(len(pulse_files))\n",
    "print(pulse_files[0].shape)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "np_pulse_lst = []\n",
    "for idx in range(len(pulse_files)):\n",
    "    pulse_files[idx] = pulse_files[idx].fillna(method='pad')\n",
    "    pulse_files[idx] = pulse_files[idx].fillna(method='bfill')\n",
    "    np_pulse = pulse_files[idx].values\n",
    "    np_pulse_lst.append(np_pulse)\n",
    "np_pulse_lst = np.array(np_pulse_lst)\n",
    "print(np_pulse_lst.shape)\n",
    "np.save(file='../../datasets/raw_pulses.npy', arr=np_pulse_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Generate Spectrogram Combinations \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np import EEGrunt import PIL\n",
    "\n",
    "PSD_per_Hz_lst = []\n",
    "\n",
    "source = 'muse-lsl' pulse_path = '../../datasets/pulse/' pulse_topath = '../../datasets/spectrogram/' title = 'Muse' file_postfix = '.csv' bp_filter = [1, 50]\n",
    "\n",
    "image_prefix = \"./plots/Muse_Spectrogram_Channel_\" image_postfix ='.jpg' image_lst = [image_prefix+'1'+image_postfix, image_prefix+'2'+image_postfix, image_prefix+'3'+image_postfix, image_prefix+'4'+image_postfix]\n",
    "\n",
    "for idx in range(len(pulse_files)):\n",
    "\n",
    "# Initalization\n",
    "file = str(idx)+file_postfix\n",
    "MuseSess = EEGrunt.EEGrunt(pulse_path, file, source, title)\n",
    "MuseSess.plot = 'save'\n",
    "MuseSess.load_data()\n",
    "\n",
    "# Process\n",
    "print(\"Processing file {}, {} of {}: ...\".format(file, idx+1, len(pulse_files)), end='')\n",
    "for channel in MuseSess.channels:\n",
    "    MuseSess.load_channel(channel)\n",
    "    MuseSess.notch_mains_interference()\n",
    "    MuseSess.data = MuseSess.bandpass(bp_filter[0], bp_filter[1])\n",
    "    MuseSess.get_spectrum_data()\n",
    "    MuseSess.spectrogram()\n",
    "\n",
    "images = [ PIL.Image.open(i) for i in image_lst ]\n",
    "# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "min_shape = sorted( [(np.sum(i.size), i.size ) for i in images])[0][1]\n",
    "images_comb = np.vstack( (np.asarray( i.resize(min_shape) ) for i in images ) )\n",
    "images_comb = PIL.Image.fromarray(images_comb)\n",
    "images_comb.save(pulse_topath+str(idx)+image_postfix)\n",
    "\n",
    "# TP10 only\n",
    "PSD_per_Hz = np.mean(MuseSess.spec_PSDperHz,1)\n",
    "PSD_per_Hz = 10.0*np.log10(PSD_per_Hz[bp_filter[0]:bp_filter[1]])\n",
    "PSD_per_Hz_lst.append(PSD_per_Hz)\n",
    "print(\" Complete.\")\n",
    "PSD_per_Hz_lst = np.array(PSD_per_Hz_lst) np.save(file='../../datasets/PSD_per_Hz_TP10.npy', arr=PSD_per_Hz_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generate PSD per Hz\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import EEGrunt\n",
    "\n",
    "PSD_per_Hz_lst = [] # (file, channel, values)\n",
    "\n",
    "source = 'muse-lsl'\n",
    "pulse_path = '../../datasets/pulse/'\n",
    "title = 'Muse'\n",
    "file_postfix = '.csv'\n",
    "bp_filter = [1, 50]\n",
    "\n",
    "for idx in range(len(pulse_files)):\n",
    "    \n",
    "    # Initalization\n",
    "    file = str(idx)+file_postfix\n",
    "    MuseSess = EEGrunt.EEGrunt(pulse_path, file, source, title)\n",
    "    MuseSess.plot = 'show'\n",
    "    MuseSess.load_data()\n",
    "    \n",
    "    # Process\n",
    "    print(\"Processing file {}, {} of {}: ...\".format(file, idx+1, len(pulse_files)), end='')\n",
    "    channels = []\n",
    "    for channel in MuseSess.channels:\n",
    "        MuseSess.load_channel(channel)\n",
    "        MuseSess.notch_mains_interference()\n",
    "        MuseSess.data = MuseSess.bandpass(bp_filter[0], bp_filter[1])\n",
    "        MuseSess.get_spectrum_data()\n",
    "        \n",
    "        PSD_per_Hz = np.mean(MuseSess.spec_PSDperHz,1)\n",
    "        PSD_per_Hz = 10.0*np.log10(PSD_per_Hz[bp_filter[0]:bp_filter[1]])\n",
    "        channels.append(PSD_per_Hz)\n",
    "        \n",
    "    PSD_per_Hz_lst.append(channels)\n",
    "    print(\" Complete.\")\n",
    "PSD_per_Hz_lst = np.array(PSD_per_Hz_lst)\n",
    "np.save(file='../../datasets/PSD_per_Hz.npy', arr=PSD_per_Hz_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generate bandpower per unit time\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import EEGrunt\n",
    "\n",
    "eegbands = {\n",
    "    'Delta': (0, 4),\n",
    "    'Theta': (4, 8),\n",
    "    'Alpha': (8, 12),\n",
    "    'Beta' : (12, 30),\n",
    "    'Gamma': (30, 50)\n",
    "}\n",
    "power_per_band_lst = [] # (file, channel, bands, values) --> i.e. (file, features, timesteps):: features is channelXbands; timesteps is values\n",
    "\n",
    "source = 'muse-lsl'\n",
    "pulse_path = '../../datasets/pulse/'\n",
    "title = 'Muse'\n",
    "file_postfix = '.csv'\n",
    "\n",
    "for idx in range(len(pulse_files)):\n",
    "    \n",
    "    # Initalization\n",
    "    file = str(idx)+file_postfix\n",
    "    MuseSess = EEGrunt.EEGrunt(pulse_path, file, source, title)\n",
    "    MuseSess.plot = 'show'\n",
    "    MuseSess.load_data()\n",
    "    \n",
    "    # Process\n",
    "    print(\"Processing file {}, {} of {}: ...\".format(file, idx+1, len(pulse_files)), end='')\n",
    "    \n",
    "    channels = []\n",
    "    for channel in MuseSess.channels:\n",
    "        MuseSess.load_channel(channel)\n",
    "        MuseSess.notch_mains_interference()\n",
    "        MuseSess.data = MuseSess.bandpass(bp_filter[0], bp_filter[1])\n",
    "        MuseSess.get_spectrum_data()\n",
    "        \n",
    "        PSD_per_bin = MuseSess.spec_PSDperBin\n",
    "        freqs = MuseSess.spec_freqs\n",
    "        \n",
    "        bands = []\n",
    "        for band in eegbands:\n",
    "            frange = (freqs > eegbands[band][0]) & (freqs < eegbands[band][1])\n",
    "            bandpower = np.sqrt(np.sum(PSD_per_bin[frange], 0))\n",
    "            bands.append(bandpower)\n",
    "        channels.append(bands)\n",
    "    power_per_band_lst.append(channels)\n",
    "    print(\" Complete.\")\n",
    "power_per_band_lst = np.array(power_per_band_lst)\n",
    "np.save(file='../../datasets/Power_per_band.npy', arr=power_per_band_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
