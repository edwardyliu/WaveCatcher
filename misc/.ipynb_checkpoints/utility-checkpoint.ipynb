{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import math\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_intervals(rate, samples, frame_duration, overlap):\n",
    "    \"\"\"\n",
    "    Get the intervals of each frame in the dataset\n",
    "    :param rate: sampling rate of device (in Hz)\n",
    "    :param samples: number of samples in the session\n",
    "    :param frame_duration: desired duration of frame in seconds\n",
    "    :param overlap: a float that represents a fraction of the frame that can overlap [0, 1)\n",
    "    \n",
    "    :return: list of tuple ranges i.e. intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    dataIndex = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = rate * frame_duration\n",
    "    while dataIndex + samples_per_frame <= samples:\n",
    "        intervals.append( (dataIndex, int(dataIndex + samples_per_frame) ) )\n",
    "        dataIndex = dataIndex + int(samples_per_frame) - int(overlap * samples_per_frame)\n",
    "    \n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intv = get_frame_intervals(128.0, 1000, 3, 0)\n",
    "print(intv)\n",
    "print(intv[0][0])\n",
    "print(intv[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10\n",
    "lst = np.arange(length)\n",
    "T = length/128.0\n",
    "freqs = lst/T\n",
    "freqs = freqs[range(length//2)]\n",
    "\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(snippet, rate):\n",
    "    \"\"\"\n",
    "    Get the frequencies and FFT values given the data snippet and the sampling rate of the data\n",
    "    :param snippet: a data frame of a particular channel i.e. electrode\n",
    "    :param rate: sampling rate of data\n",
    "    \n",
    "    :return freqs: an array of frequencies of the FFT\n",
    "    :return Y: an array of FFT values\n",
    "    \"\"\"\n",
    "    \n",
    "    length = len(snippet)\n",
    "    lst = np.arange(length)\n",
    "    T = float(length) / float(rate)\n",
    "    freqs = lst / T\n",
    "    freqs = freqs[range(length//2)] # // ==> floor division\n",
    "    \n",
    "    Y = np.fft.fft(snippet) / float(length)\n",
    "    Y = Y[range(length//2)]\n",
    "    \n",
    "    return freqs, abs(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EEG_bands(freqs, Y):\n",
    "    \"\"\"\n",
    "    Get EEG bandwave averages given FFT\n",
    "    :param freqs: frequencies of FFT\n",
    "    :param Y: value of FFT\n",
    "    \n",
    "    :return: delta, theta, alpha, beta, and gamma averages\n",
    "    \"\"\"\n",
    "    delta_range = (0,4)\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,14)\n",
    "    beta_range = (14,32)\n",
    "    gamma_range = (32,50)\n",
    "    \n",
    "    delta = Y[(freqs>delta_range[0]) & (freqs<=delta_range[1])].mean()\n",
    "    theta = Y[(freqs>theta_range[0]) & (freqs<=theta_range[1])].mean()\n",
    "    alpha = Y[(freqs>alpha_range[0]) & (freqs<=alpha_range[1])].mean()\n",
    "    beta = Y[(freqs>beta_range[0]) & (freqs<=beta_range[1])].mean()\n",
    "    gamma = Y[(freqs>gamma_range[0]) & (freqs<=gamma_range[1])].mean()\n",
    "    return delta, theta, alpha, beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 8, 5\n",
    "matrix = np.array([[0 for x in range(w)] for y in range(h)])\n",
    "\n",
    "print(matrix)\n",
    "print(matrix.shape)\n",
    "matrix[0][0] = 5\n",
    "matrix[0][1] = 6\n",
    "matrix[0][7] = 9\n",
    "print(matrix)\n",
    "print(matrix.shape)\n",
    "print(\"list\")\n",
    "\n",
    "for lst in matrix:\n",
    "    print(lst[0:5])\n",
    "print(matrix.shape[0]) \n",
    "print(matrix.shape[1])\n",
    "\n",
    "tmp1 = []\n",
    "tmp1.append([1,2,3,4,5])\n",
    "tmp1.append([2,3,4,5,6])\n",
    "tmp1 = np.transpose(np.array(tmp1))\n",
    "tmp2 = []\n",
    "tmp2.append([0,0,0,0,0])\n",
    "tmp2.append([1,1,1,1,1])\n",
    "tmp2 = np.transpose(np.array(tmp2))\n",
    "tmp3 = []\n",
    "tmp3.append(tmp1)\n",
    "tmp3.append(tmp2)\n",
    "tmp3 = np.array(tmp3)\n",
    "print(\"frames\")\n",
    "print(tmp3)\n",
    "print(\"frame 0 i.e. sample 0\")\n",
    "print(tmp3[0])\n",
    "print(\"band 0 (delta) of frame 0\")\n",
    "print(tmp3[0][0])\n",
    "print(\"electrode 0 of band 0 (delta) of frame 0\")\n",
    "print(tmp3[0][0][0])\n",
    "tmp3 = tmp3.reshape(len(tmp3), -1)\n",
    "print(tmp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(dataframe, rate, frame_duration, overlap):\n",
    "    \"\"\"\n",
    "    Get the data of each frame in the dataframe\n",
    "    :param dataframe: array of data with all channels (i.e. electrodes) of a session\n",
    "        shape: [m-electrodes, eeg signals in topological order ==> time-based]\n",
    "    :param rate: sampling rate of device (in Hz)\n",
    "    :param frame_duration: desired frame duration in seconds\n",
    "    :param overlap: a float that represents a fraction of the frame that can overlap [0, 1)\n",
    "    \n",
    "    :return: np-array of delta, theta, alpha, beta, and gamma averages for each electrode (i.e. channel) of each time step (i.e. frame interval)\n",
    "        shape: [m-frames, n-bands, o-electrodes]\n",
    "    \"\"\"\n",
    "    \n",
    "    samples_per_frame = rate * frame_duration\n",
    "    frames = []\n",
    "    intervals = get_frame_intervals(rate, dataframe.shape[1], frame_duration, overlap)\n",
    "    \n",
    "    for i,_ in enumerate(intervals):\n",
    "        frame = []\n",
    "        for channel in dataframe: # channel ==> electrode\n",
    "            snippet = channel[intervals[i][0]:intervals[i][1]]\n",
    "            freqs, Y = get_fft(snippet)\n",
    "            delta, theta, alpha, beta, gamma = get_EEG_bands(freqs, Y)\n",
    "            frame.append([delta, theta, alpha, beta, gamma])\n",
    "        frame = np.transpose(np.array(frame))\n",
    "        frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_images(locations, features, img_size, normalize=True):\n",
    "    \"\"\"\n",
    "    Generate EEG images given the electrode locations in 2D space and feature values for each electrode\n",
    "    :param locations: an array containing the x and y coorindate locations of each electrode\n",
    "        shape: [# of electrodes, 2]\n",
    "    :param features: the feature matrix\n",
    "        shape: [# of frames i.e. intervals, features]\n",
    "        format of features: [delta1, delta2, ..., deltaN, theta1, theta2, ..., thetaN, ..., gamma1, gamma2, ..., gammaN]\n",
    "    :param img_size: number of pixels in the output images\n",
    "    :param normalize: flag for whether to normalize each band over all samples or not\n",
    "    \n",
    "    TODO in Future:\n",
    "    :param augment: flag for generating augmented images\n",
    "    :param pca: flag for PCA based data augmentation\n",
    "    :param std_mult: multiplier for added noise\n",
    "    :param n_components: number of components in PCA to retain for augmentation\n",
    "    \n",
    "    :return: the generated images\n",
    "        shape: [samples, colors, width, height]\n",
    "    \"\"\"\n",
    "    img_size\n",
    "    # check whether feature size is divisible by the number of electrodes i.e. channels\n",
    "    assert features.shape[1] % locations.shape[0] == 0\n",
    "    \n",
    "    feats = []\n",
    "    colors = features.shape[1] // locations.shape[0] # number of bands\n",
    "    for color in range(colors):\n",
    "        feats.append(features[:, color * locations.shape[0] : (color+1) * locations.shape[0] - 1])\n",
    "    \n",
    "    samples = features.shape[0]\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "        min(locations[:, 0]):max(locations[:, 0]):img_size*1j,\n",
    "        min(locations[:, 1]):max(locations[:, 1]):img_size*1j\n",
    "    ]\n",
    "    \n",
    "    interpolations = []\n",
    "    for color in range(colors):\n",
    "        interpolations.append(np.zeros([samples, img_size, img_size]))\n",
    "    \n",
    "    for sample in range(samples):\n",
    "        for color in range(colors):\n",
    "            interpolations[color][sample, :, :] = griddata(locations, feats[color][sample, :], (grid_x, grid_y), method='cubic', fill_value=np.nan)\n",
    "        print(\"Interpolating \" + str(sample+1) + \" of \" + str(samples))\n",
    "    \n",
    "    for color in range(colors):\n",
    "        if normalize:\n",
    "            interpolation[color][~np.isnan(interpolation[color])] = scale(interpolation[color][~np.isnan(interpolation[color])])\n",
    "        interpolation[color] = np.nan_to_num(interpolation[color])\n",
    "    \n",
    "    return np.swapaxes(np.asarray(interpolation), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(filenames, labels, img_size, locations, rate, frame_duration, overlap):\n",
    "    \"\"\"\n",
    "    Get the array of frames and their respective labels\n",
    "    :param filenames: list of strings for each input datafile (needs to formatted)\n",
    "    :param labels: list of labels for each input datafile (in-order)\n",
    "    :param img_size: int size of output images in the form (n, n)\n",
    "    :param locations: an array containing the x and y coorindate locations of each electrode\n",
    "        shape: [# of electrodes, 2]\n",
    "    :param rate: sampling rate of device (in Hz)\n",
    "    :param frame_duration: desired frame duration in seconds\n",
    "    :param overlap: a float that represents a fraction of the frame that can overlap [0, 1)\n",
    "    \n",
    "    :return data: np-array of image frames (unshuffled)\n",
    "    :return Y: np-array of labels for each frame respectively (1 or 0)\n",
    "    \"\"\"\n",
    "    \n",
    "    samples_per_frame = rate * frame_duration\n",
    "    print(\"Data Pipeline: Generating...\")\n",
    "    \n",
    "    data = []\n",
    "    Y = []\n",
    "    for i, file in enumerate(filenames):\n",
    "        print(\"Processing file: \" + file + \" [\" + str(i+1) + \" of \" + str(len(filenames)) + \"]\")\n",
    "        data = np.genfromtxt(file, delimiter=',')\n",
    "        \n",
    "        # TODO Now: format csv files\n",
    "        formatted_data = data\n",
    "        \n",
    "        X = get_frames(formatted_data, rate, frame_duration, overlap)\n",
    "        X = X.reshape(len(X), -1)\n",
    "        \n",
    "        images = gen_images(np.array(locations), X, img_size, normalize=False)\n",
    "        print(str(len(images)) + \" frames were generated with label \" + str(labels[i]) + \".\")\n",
    "        if i == 0:\n",
    "            data = images\n",
    "            Y = np.ones(len(images)) * labels[i]\n",
    "        else:\n",
    "            data = np.concatenate((data, images), axis=0)\n",
    "            Y = np.concatenate((Y, np.ones(len(images)) * labels[i]), axis=0)\n",
    "            \n",
    "    return np.array(data), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['data/ED001_T.csv',\n",
    "              'data/ED001_N.csv',\n",
    "              'data/ED002_T.csv',\n",
    "              'data/ED002_N.csv']\n",
    "labels = [1,0,1,0]\n",
    "img_size = 28\n",
    "location_2d = [(-2.0,2.0),\n",
    "               (1.0,3.0),\n",
    "               (-1.0,3.0),\n",
    "               (4.0,1.0)]\n",
    "rate = 128.0\n",
    "frame_duration = 1.0\n",
    "overlap = 0.25\n",
    "X, Y = data_pipeline(filenames, labels, img_size, location_2d, rate, frame_duration, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
