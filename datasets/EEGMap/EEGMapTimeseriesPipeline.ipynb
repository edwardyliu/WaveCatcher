{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1552683620495_recording.csv', '1552684135826_recording.csv', '1552684518897_recording.csv', '1552684885683_recording.csv', '1552685274491_recording.csv', '1552686579599_recording.csv', '1552687068355_recording.csv', '1552687461872_recording.csv', '1552687730763_recording.csv', '1552688006554_recording.csv', '1552684886225_recording.csv', '1552685478381_recording.csv', '1552685952146_recording.csv', '1552686877018_recording.csv', '1552687454762_recording.csv', '1552687746756_recording.csv', '1552882289936_recording.csv', '1550862070278_recording.csv', '1551117337203_recording.csv', '1551117646871_recording.csv', '1551118061985_recording.csv', '1551118320943_recording.csv', '1551249571278_recording.csv', '1553039903059_recording.csv', '1553040206684_recording.csv', '1553040672641_recording.csv', '1553041018556_recording.csv', '1553041309127_recording.csv', '1553041571909_recording.csv', '1553041964221_recording.csv', '1553042270815_recording.csv', '1553042628553_recording.csv', '1552687266553_recording.csv', '1552687653488_recording.csv', '1552687968261_recording.csv', '1552793083454_recording.csv', '1552793419397_recording.csv', '1552794169380_recording.csv', '1552794648660_recording.csv']\n",
      "[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Load metadata\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "files = []\n",
    "activities = []\n",
    "persons = [\"Ashima Gupta\", \"Achinth Venkat\", \"Oishe Farhan\", \"Liu Edward\"]\n",
    "with open('../raw/users.json') as jsonfile:\n",
    "    metadata = json.load(jsonfile)\n",
    "    for person in persons:\n",
    "        #print(person)\n",
    "        for session in metadata[person]['sessions']:\n",
    "            activity = metadata[person]['sessions'][session]['activity']\n",
    "            #print(activity, end=': ')\n",
    "            #print(session)\n",
    "            files.append(session)\n",
    "            activities.append(activity)\n",
    "        #print()\n",
    "labels = []\n",
    "for idx in range(len(activities)):\n",
    "    if activities[idx] == 'Simon':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "print(files)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from functools import reduce\n",
    "import math as m\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import scipy.stats as scs\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "               augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "\n",
    "    :param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
    "                        coordinates for each electrode.\n",
    "    :param features: Feature matrix as [n_samples, n_features]\n",
    "                                Features are as columns.\n",
    "                                Features corresponding to each frequency band are concatenated.\n",
    "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "    :param n_gridpoints: Number of pixels in the output images\n",
    "    :param normalize:   Flag for whether to normalize each band over all samples\n",
    "    :param augment:     Flag for generating augmented images\n",
    "    :param pca:         Flag for PCA based data augmentation\n",
    "    :param std_mult     Multiplier for std of added noise\n",
    "    :param n_components: Number of components in PCA to retain for augmentation\n",
    "    :param edgeless:    If True generates edgeless images by adding artificial channels\n",
    "                        at four corners of the image with value = 0 (default=False).\n",
    "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
    "                        images.\n",
    "    \"\"\"\n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    n_colors = features.shape[1] // nElectrodes\n",
    "    for c in range(int(n_colors)):\n",
    "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
    "    if augment:\n",
    "        if pca:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=True, n_components=n_components)\n",
    "        else:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=False, n_components=n_components)\n",
    "    nSamples = features.shape[0]\n",
    "    # Interpolate the values\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([nSamples, n_gridpoints, n_gridpoints]))\n",
    "    # Generate edgeless images\n",
    "    if edgeless:\n",
    "        min_x, min_y = np.min(locs, axis=0)\n",
    "        max_x, max_y = np.max(locs, axis=0)\n",
    "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y],[max_x, min_y],[max_x, max_y]]),axis=0)\n",
    "        for c in range(n_colors):\n",
    "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((nSamples, 4)), axis=1)\n",
    "    # Interpolating\n",
    "    for i in range(nSamples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                    method='cubic', fill_value=np.nan)\n",
    "        print('Interpolating {0}/{1}\\r'.format(i+1, nSamples), end='\\r')\n",
    "    # Normalizing\n",
    "    for c in range(n_colors):\n",
    "        if normalize:\n",
    "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
    "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
    "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
    "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
    "\n",
    "def get_fft(snippet):\n",
    "    Fs = 256.0;  # sampling rate\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    y = snippet\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    return frq,abs(Y)\n",
    "\n",
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,32)\n",
    "    theta = Y[(f>=theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>=alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>=beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta\n",
    "\n",
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds \n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 256\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals\n",
    "\n",
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 256.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "            \n",
    "        frames.append(frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "def make_data_pipeline(path,file_names,labels,image_size,pulse_per_frame,frame_duration,overlap, locs_2d):\n",
    "    '''\n",
    "    IN: \n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    ##################################\n",
    "    ###Still need to do the overlap###!!!\n",
    "    ##################################\n",
    "    \n",
    "    Fs = 256.0   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "    \n",
    "    print('Generating training data...')\n",
    "\n",
    "    trim = 5\n",
    "    \n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        \n",
    "        df = pd.read_csv(path+file)\n",
    "        df = df.loc[:, ['TP9', 'AF7', 'AF8', 'TP10']]\n",
    "        df = df.truncate(before=trim*Fs, after=df.shape[0]-trim*Fs-1)\n",
    "        buffer = df.values\n",
    "        df = pd.DataFrame(buffer)\n",
    "        \n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),4*3) # 14 electrodes for test dataset\n",
    "        \n",
    "        images = gen_images(np.array(locs_2d), X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3)\n",
    "        \n",
    "        nImages = len(images)\n",
    "        pulses = []\n",
    "        start = 0\n",
    "        for end in range(pulse_per_frame, nImages, pulse_per_frame):\n",
    "            if (end+pulse_per_frame) >= nImages:\n",
    "                pulses.append(images[nImages-pulse_per_frame:nImages,:])\n",
    "            else:\n",
    "                pulses.append(images[start:end,:])\n",
    "            start = end\n",
    "        pulses = np.array(pulses)\n",
    "        \n",
    "        print(nImages, ' frames generated with label ', labels[i], '.')\n",
    "        print(len(pulses), ' frame pulses generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = pulses\n",
    "            y = np.ones(len(pulses))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,pulses),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(pulses))*labels[i]),axis = 0)\n",
    "        \n",
    "    return X,np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  1552683620495_recording.csv . ( 1  of  39 )\n",
      "982  frames generated with label  1 .\n",
      "98  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552684135826_recording.csv . ( 2  of  39 )\n",
      "365  frames generated with label  0 .\n",
      "36  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552684518897_recording.csv . ( 3  of  39 )\n",
      "424  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552684885683_recording.csv . ( 4  of  39 )\n",
      "424  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552685274491_recording.csv . ( 5  of  39 )\n",
      "424  frames generated with label  1 .\n",
      "42  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552686579599_recording.csv . ( 6  of  39 )\n",
      "529  frames generated with label  1 .\n",
      "52  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552687068355_recording.csv . ( 7  of  39 )\n",
      "365  frames generated with label  0 .\n",
      "36  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552687461872_recording.csv . ( 8  of  39 )\n",
      "374  frames generated with label  0 .\n",
      "37  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552687730763_recording.csv . ( 9  of  39 )\n",
      "374  frames generated with label  0 .\n",
      "37  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552688006554_recording.csv . ( 10  of  39 )\n",
      "374  frames generated with label  0 .\n",
      "37  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552684886225_recording.csv . ( 11  of  39 )\n",
      "430  frames generated with label  1 .\n",
      "42  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552685478381_recording.csv . ( 12  of  39 )\n",
      "407  frames generated with label  0 .\n",
      "40  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552685952146_recording.csv . ( 13  of  39 )\n",
      "430  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552686877018_recording.csv . ( 14  of  39 )\n",
      "986  frames generated with label  1 .\n",
      "98  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552687454762_recording.csv . ( 15  of  39 )\n",
      "426  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552687746756_recording.csv . ( 16  of  39 )\n",
      "392  frames generated with label  0 .\n",
      "39  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552882289936_recording.csv . ( 17  of  39 )\n",
      "532  frames generated with label  1 .\n",
      "53  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1550862070278_recording.csv . ( 18  of  39 )\n",
      "391  frames generated with label  0 .\n",
      "39  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1551117337203_recording.csv . ( 19  of  39 )\n",
      "428  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1551117646871_recording.csv . ( 20  of  39 )\n",
      "427  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1551118061985_recording.csv . ( 21  of  39 )\n",
      "391  frames generated with label  0 .\n",
      "39  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1551118320943_recording.csv . ( 22  of  39 )\n",
      "365  frames generated with label  0 .\n",
      "36  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1551249571278_recording.csv . ( 23  of  39 )\n",
      "428  frames generated with label  1 .\n",
      "42  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1553039903059_recording.csv . ( 24  of  39 )\n",
      "980  frames generated with label  1 .\n",
      "97  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1553040206684_recording.csv . ( 25  of  39 )\n",
      "422  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553040672641_recording.csv . ( 26  of  39 )\n",
      "389  frames generated with label  0 .\n",
      "38  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553041018556_recording.csv . ( 27  of  39 )\n",
      "493  frames generated with label  0 .\n",
      "49  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553041309127_recording.csv . ( 28  of  39 )\n",
      "405  frames generated with label  0 .\n",
      "40  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553041571909_recording.csv . ( 29  of  39 )\n",
      "373  frames generated with label  0 .\n",
      "37  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553041964221_recording.csv . ( 30  of  39 )\n",
      "365  frames generated with label  0 .\n",
      "36  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553042270815_recording.csv . ( 31  of  39 )\n",
      "424  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1553042628553_recording.csv . ( 32  of  39 )\n",
      "490  frames generated with label  0 .\n",
      "48  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552687266553_recording.csv . ( 33  of  39 )\n",
      "522  frames generated with label  1 .\n",
      "52  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552687653488_recording.csv . ( 34  of  39 )\n",
      "522  frames generated with label  1 .\n",
      "52  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552687968261_recording.csv . ( 35  of  39 )\n",
      "420  frames generated with label  0 .\n",
      "41  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552793083454_recording.csv . ( 36  of  39 )\n",
      "429  frames generated with label  0 .\n",
      "42  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552793419397_recording.csv . ( 37  of  39 )\n",
      "429  frames generated with label  1 .\n",
      "42  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  1552794169380_recording.csv . ( 38  of  39 )\n",
      "367  frames generated with label  0 .\n",
      "36  frame pulses generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  1552794648660_recording.csv . ( 39  of  39 )\n",
      "367  frames generated with label  1 .\n",
      "36  frame pulses generated with label  1 .\n",
      "\n",
      "\n",
      "(1785, 10, 24, 24, 3)\n",
      "(1785,)\n"
     ]
    }
   ],
   "source": [
    "filepath = '../raw/'\n",
    "\n",
    "img_size = 24\n",
    "locs_2d = [(-2.0,-1.0), # TP9\n",
    "            (-2.0,2.0),  # AF7\n",
    "            (2.0,2.0),   # AF8\n",
    "            (2.0,-1.0)]  # TP10\n",
    "\n",
    "pulse_per_frame = 10\n",
    "frame_duration = 1.\n",
    "overlap = 0.25\n",
    "\n",
    "X, y = make_data_pipeline(filepath, files, labels, img_size, pulse_per_frame, frame_duration, overlap, locs_2d)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the returned result should be a (sample, pulse_per_frame, img_size, img_size, rgb channels) np array\n",
    "# i.e. (sample, time, img_size, img_size, rgb channels)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "idx = 100\n",
    "time = 5\n",
    "print(y[idx])\n",
    "plt.imshow(X[idx][time])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Save as npy\n",
    "\"\"\"\n",
    "\n",
    "np.save('EEGMapTimeseries_10F_1S.npy', X)\n",
    "np.save('EEGMapTimeseries_10F_1S_Labels.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
